"""
Streamlit Dashboard for AI Trend Monitoring - REAL-TIME DYNAMIC VERSION
è¿æ¥Kafkaå®æ—¶æ•°æ®ï¼ŒåŒ…å«æ‰€æœ‰åŠ¨æ€å…ƒç´ 
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
import sys
import os

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from kafka_reader import KafkaDataReader
    KAFKA_AVAILABLE = True
except Exception as e:
    KAFKA_AVAILABLE = False

# Page configuration
st.set_page_config(
    page_title="AI Trend Monitor - Live",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å¢å¼ºCSS - æ·»åŠ åŠ¨ç”»æ•ˆæœ
st.markdown("""
<style>
    /* ä¸»æ ‡é¢˜ */
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        text-align: center;
        padding: 1rem 0;
    }

    /* æ•°å­—æ»šåŠ¨åŠ¨ç”» */
    @keyframes countUp {
        from {
            opacity: 0;
            transform: translateY(20px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }

    .metric-value {
        animation: countUp 0.5s ease-out;
    }

    /* æ–°æ•°æ®é—ªçƒåŠ¨ç”» */
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; }
    }

    .new-badge {
        background: linear-gradient(45deg, #4CAF50, #8BC34A);
        color: white;
        padding: 4px 12px;
        border-radius: 12px;
        font-size: 0.9rem;
        font-weight: bold;
        animation: pulse 2s infinite;
        display: inline-block;
    }

    /* å®æ—¶çŠ¶æ€ç¯ */
    @keyframes blink {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.3; }
    }

    .live-indicator {
        display: inline-block;
        width: 10px;
        height: 10px;
        background-color: #FF5252;
        border-radius: 50%;
        margin-right: 8px;
        animation: blink 1.5s infinite;
    }

    /* è¿›åº¦æ¡æ ·å¼ */
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #1E88E5, #42A5F5);
    }

    /* é«˜äº®æ–°æ•°æ®è¡Œ */
    .recent-data-highlight {
        background-color: #E8F5E9 !important;
        border-left: 4px solid #4CAF50 !important;
        animation: fadeIn 0.5s ease-in;
    }

    @keyframes fadeIn {
        from { opacity: 0; }
        to { opacity: 1; }
    }

    /* å®æ—¶æ—¶é’Ÿæ ·å¼ */
    .realtime-clock {
        font-size: 1.1rem;
        font-weight: 500;
        color: #424242;
    }

    /* å€’è®¡æ—¶æ ·å¼ */
    .countdown {
        font-size: 1.0rem;
        color: #FF9800;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)


# åˆå§‹åŒ– session_state
if 'previous_count' not in st.session_state:
    st.session_state.previous_count = 0
if 'last_refresh' not in st.session_state:
    st.session_state.last_refresh = time.time()


@st.cache_data(ttl=5)  # ç¼“å­˜5ç§’ï¼ˆå¿«é€Ÿåˆ·æ–°ï¼‰
def load_real_data():
    """ä»KafkaåŠ è½½å®æ—¶æ•°æ®"""
    if not KAFKA_AVAILABLE:
        return None, 0

    try:
        reader = KafkaDataReader(
            bootstrap_servers='localhost:9092',
            topic='ai-social-raw'
            # ç§»é™¤ max_messages é™åˆ¶ï¼Œè¯»å–å…¨éƒ¨æ•°æ®
        )

        # è·å–æ€»æ¶ˆæ¯æ•°ï¼ˆå¿«é€Ÿï¼‰
        total_count = reader.get_message_count()

        # è·å–æ‰€æœ‰æ¶ˆæ¯
        messages = reader.get_all_messages()

        if not messages:
            return None, total_count

        df = reader.parse_to_dataframe(messages)

        if df.empty:
            return None, total_count

        return df, total_count

    except Exception as e:
        st.error(f"Error loading data: {e}")
        return None, 0


def analyze_trending_topics(df):
    """åˆ†æçƒ­é—¨è¯é¢˜"""
    if df is None or df.empty:
        return pd.DataFrame()

    keywords = ['GPT', 'Claude', 'LLM', 'ChatGPT', 'OpenAI', 'AI', 'Anthropic',
                'Gemini', 'Llama', 'Machine Learning', 'Deep Learning']

    topic_counts = []

    for keyword in keywords:
        count = df['text'].str.contains(keyword, case=False, na=False).sum()
        if count > 0:
            topic_counts.append({
                'topic': keyword,
                'mentions': count
            })

    return pd.DataFrame(topic_counts).sort_values('mentions', ascending=False)


def main():
    """ä¸»åº”ç”¨"""

    # === é¡¶éƒ¨çŠ¶æ€æ  ===
    col_time, col_countdown, col_btn = st.columns([2, 2, 1])

    with col_time:
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        st.markdown(f'<div class="realtime-clock">â° <b>å½“å‰æ—¶é—´</b>: {current_time}</div>',
                   unsafe_allow_html=True)

    with col_countdown:
        # è®¡ç®—ä¸‹æ¬¡åˆ·æ–°å€’è®¡æ—¶
        elapsed = time.time() - st.session_state.last_refresh
        next_refresh = max(0, 5 - int(elapsed))
        st.markdown(f'<div class="countdown">â³ <b>ä¸‹æ¬¡åˆ·æ–°</b>: {next_refresh} ç§’</div>',
                   unsafe_allow_html=True)

        # è¿›åº¦æ¡
        progress = min(1.0, elapsed / 5)
        st.progress(progress)

    with col_btn:
        if st.button("ğŸ”„ ç«‹å³åˆ·æ–°"):
            st.cache_data.clear()
            st.session_state.last_refresh = time.time()
            st.rerun()

    st.markdown("---")

    # === ä¸»æ ‡é¢˜ ===
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown('<div class="main-header">ğŸ¤– AI Trend Monitor</div>', unsafe_allow_html=True)
        st.markdown("""
            <center>
                <span class="live-indicator"></span>
                <span style="font-size: 1.1rem; font-weight: 600; color: #FF5252;">LIVE DATA</span>
            </center>
        """, unsafe_allow_html=True)

    st.markdown("Real-time monitoring of AI discussions from Twitter and Reddit")

    # === ä¾§è¾¹æ  ===
    with st.sidebar:
        st.header("âš™ï¸ Settings")

        auto_refresh = st.checkbox("Auto-refresh", value=True)

        st.markdown("---")

        st.subheader("ğŸ“Š Data Sources")

        if KAFKA_AVAILABLE:
            st.success("âœ… Kafka Connected")
        else:
            st.error("âŒ Kafka Unavailable")

        st.markdown("---")

        # æ˜¾ç¤ºé‡‡é›†å™¨çŠ¶æ€
        st.subheader("ğŸ¤– Collectors Status")
        st.markdown("- ğŸ¦ **Twitter**: â¸ï¸ æš‚åœï¼ˆé¿å…é™æµï¼‰")
        st.markdown("- ğŸ¤– **Reddit**: âœ… è¿è¡Œä¸­")
        st.caption("ğŸ“¡ é‡‡é›†é¢‘ç‡: 60ç§’/æ¬¡")

    # === åŠ è½½æ•°æ® ===
    with st.spinner("ğŸ“Š Loading real-time data from Kafka..."):
        df, total_count = load_real_data()

    # === è®¡ç®—æ–°å¢æ•°æ® ===
    new_data_count = total_count - st.session_state.previous_count
    if new_data_count != 0:
        st.session_state.previous_count = total_count

    # === æ˜¾ç¤ºæ–°å¢æç¤º ===
    if new_data_count > 0:
        st.markdown(f"""
            <div style="text-align: center; margin: 1rem 0;">
                <span class="new-badge">ğŸ†• æ–°å¢ +{new_data_count} æ¡æ•°æ®ï¼</span>
            </div>
        """, unsafe_allow_html=True)

    # === æ•°æ®æ£€æŸ¥ ===
    if df is None or df.empty:
        st.error("âš ï¸ No data available")
        st.info("ğŸ’¡ æ•°æ®æ­£åœ¨é‡‡é›†ä¸­ï¼Œè¯·ç¨ç­‰...")
        st.markdown(f"**Kafkaæ€»æ¶ˆæ¯æ•°**: {total_count}")
        return

    # === æ•°æ®ç»Ÿè®¡ ===
    total_posts = len(df)
    twitter_count = len(df[df['source'] == 'Twitter'])
    reddit_count = len(df[df['source'] == 'Reddit'])
    total_engagement = df['engagement'].sum()

    # === æ ¸å¿ƒæŒ‡æ ‡ ===
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        delta_str = f"+{new_data_count}" if new_data_count > 0 else None
        st.metric(
            label="ğŸ“Š Total Posts",
            value=f"{total_posts:,}",
            delta=delta_str
        )

    with col2:
        pct = f"{twitter_count/total_posts*100:.1f}%" if total_posts > 0 else "0%"
        st.metric(
            label="ğŸ¦ Twitter Posts",
            value=f"{twitter_count:,}",
            delta=pct
        )

    with col3:
        pct = f"{reddit_count/total_posts*100:.1f}%" if total_posts > 0 else "0%"
        st.metric(
            label="ğŸ¤– Reddit Posts",
            value=f"{reddit_count:,}",
            delta=pct
        )

    with col4:
        st.metric(
            label="ğŸ’¬ Total Engagement",
            value=f"{total_engagement:,}",
            delta="Live"
        )

    st.markdown("---")

    # === ä¸»è¦å†…å®¹åŒº ===
    col_left, col_right = st.columns([3, 2])

    with col_left:
        st.subheader("ğŸ”¥ Trending Topics (from Real Data)")

        topics_df = analyze_trending_topics(df)

        if not topics_df.empty:
            # å¸¦åŠ¨ç”»çš„æŸ±çŠ¶å›¾
            fig = px.bar(
                topics_df.head(10),
                x='topic',
                y='mentions',
                title='Most Mentioned Topics',
                labels={'mentions': 'Mentions', 'topic': 'Topic'},
                color='mentions',
                color_continuous_scale='Blues'
            )

            fig.update_layout(
                xaxis_tickangle=-45,
                showlegend=False,
                height=400,
                transition_duration=500  # è¿‡æ¸¡åŠ¨ç”»
            )

            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No trending topics found yet")

    with col_right:
        st.subheader("ğŸ“Š Data Source Distribution")

        # é¥¼å›¾
        source_counts = df['source'].value_counts()

        fig = px.pie(
            values=source_counts.values,
            names=source_counts.index,
            title='Twitter vs Reddit',
            color_discrete_map={'Twitter': '#1DA1F2', 'Reddit': '#FF4500'}
        )

        fig.update_traces(textposition='inside', textinfo='percent+label')
        fig.update_layout(height=400)

        st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")

    # === æ˜¾ç¤ºæœ€è¿‘æ•°æ®ï¼ˆé«˜äº®æœ€è¿‘5åˆ†é’Ÿï¼‰ ===
    st.subheader("ğŸ‘¥ Most Active Authors")

    if 'author' in df.columns:
        top_authors = df.groupby('author').agg({
            'post_id': 'count',
            'engagement': 'sum'
        }).rename(columns={'post_id': 'posts', 'engagement': 'total_engagement'})
        top_authors = top_authors.sort_values('posts', ascending=False).head(10)

        st.dataframe(top_authors, use_container_width=True)

    st.markdown("---")

    # === æœ€æ–°å¸–å­åˆ—è¡¨ï¼ˆé«˜äº®æœ€è¿‘æ•°æ®ï¼‰ ===
    st.subheader("ğŸ“ Recent Posts")

    # æ ‡è®°æœ€è¿‘5åˆ†é’Ÿçš„æ•°æ®
    if 'created_at' in df.columns:
        try:
            df['created_at_parsed'] = pd.to_datetime(df['created_at'], errors='coerce')
            current_time = datetime.now()
            df['is_recent'] = (current_time - df['created_at_parsed']) < timedelta(minutes=5)
        except:
            df['is_recent'] = False
    else:
        df['is_recent'] = False

    # æ˜¾ç¤ºæœ€è¿‘20æ¡
    recent_df = df.sort_values('created_at', ascending=False).head(20) if 'created_at' in df.columns else df.head(20)

    # æ˜¾ç¤ºåˆ—
    display_cols = ['source', 'author', 'text', 'engagement']
    if 'subreddit' in recent_df.columns:
        display_cols.append('subreddit')

    display_df = recent_df[display_cols].copy()
    display_df['text'] = display_df['text'].str[:100] + '...'  # æˆªæ–­é•¿æ–‡æœ¬

    st.dataframe(
        display_df,
        use_container_width=True,
        height=400
    )

    # === é¡µè„šä¿¡æ¯ ===
    st.markdown("---")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.caption(f"ğŸ”„ Last updated: {current_time}")

    with col2:
        st.caption(f"ğŸ“Š Kafka messages: {total_count:,}")

    with col3:
        st.caption("ğŸ’¾ Data source: Kafka | âš¡ Powered by Spark")

    # === è‡ªåŠ¨åˆ·æ–°é€»è¾‘ ===
    if auto_refresh:
        # æ¯5ç§’è‡ªåŠ¨åˆ·æ–°
        if time.time() - st.session_state.last_refresh >= 5:
            st.session_state.last_refresh = time.time()
            time.sleep(0.1)
            st.rerun()


if __name__ == "__main__":
    main()
