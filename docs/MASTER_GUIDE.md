# AIè¶‹åŠ¿ç›‘æ§ç³»ç»Ÿ - å®Œæ•´æŒ‡å—

**ç‰ˆæœ¬**: v2.0 (MinIOç‰ˆæœ¬) | **æ›´æ–°æ—¥æœŸ**: 2025-11-11 | **çŠ¶æ€**: Phase 2B å®Œæˆ

---

## ç›®å½•

- [å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿï¼‰](#å¿«é€Ÿå¼€å§‹5åˆ†é’Ÿ)
- [APIé…ç½®è¯¦è§£](#apié…ç½®è¯¦è§£)
- [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
- [å®Œæ•´ä½¿ç”¨åœºæ™¯](#å®Œæ•´ä½¿ç”¨åœºæ™¯)
- [æ•…éšœæ’æŸ¥å¤§å…¨](#æ•…éšœæ’æŸ¥å¤§å…¨)
- [å‘½ä»¤é€ŸæŸ¥è¡¨](#å‘½ä»¤é€ŸæŸ¥è¡¨)
- [æ‰©å±•è·¯çº¿å›¾](#æ‰©å±•è·¯çº¿å›¾)

---

## å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿï¼‰

### å‰ç½®è¦æ±‚

- Docker Desktop (è¿è¡Œä¸­) - [ä¸‹è½½](https://www.docker.com/products/docker-desktop)
- Python 3.9+
- Twitter APIå¯†é’¥
- Reddit APIå¯†é’¥

### ä¸€é”®å¯åŠ¨å‘½ä»¤

```bash
# Step 1: å®Œæ•´é‡å¯ç³»ç»Ÿï¼ˆè‡ªåŠ¨éªŒè¯æ‰€æœ‰ç»„ä»¶ï¼‰
./scripts/01-full_restart.sh

# Step 2: å¯åŠ¨Sparkå†™å…¥MinIOï¼ˆæ–°å»ºç»ˆç«¯ï¼‰
./scripts/02-start_spark_minio.sh

# Step 3: å¯åŠ¨Dashboardï¼ˆæ–°å»ºç»ˆç«¯ï¼‰
./scripts/03-start_dashboard.sh

# Step 4: éªŒè¯ç³»ç»ŸçŠ¶æ€ï¼ˆå¯é€‰ï¼‰
./scripts/99-verify_system.sh
```

### è®¿é—®ç‚¹

| æœåŠ¡ | URL | ç”¨æˆ·å/å¯†ç  |
|------|-----|------------|
| Spark Master | http://localhost:8080 | - |
| Spark Worker | http://localhost:8081 | - |
| MinIO Console | http://localhost:9001 | minioadmin/minioadmin |
| Dashboard | http://localhost:8501 | - |
| Spark App UI | http://localhost:4040 | (Sparkè¿è¡Œå) |

---

## APIé…ç½®è¯¦è§£

### Twitter API ç”³è¯·

1. è®¿é—® [Twitter Developer Portal](https://developer.twitter.com/en/portal/dashboard)
2. åˆ›å»ºæ–°App
3. è·å– **Bearer Token** (Essential accesså³å¯)

### Reddit API ç”³è¯·

1. è®¿é—® [Reddit Apps](https://www.reddit.com/prefs/apps)
2. ç‚¹å‡» "Create App" æˆ– "Create Another App"
3. å¡«å†™ä¿¡æ¯:
   - **name**: ä»»æ„åç§°ï¼ˆå¦‚ "AI Trend Monitor"ï¼‰
   - **App type**: é€‰æ‹© **"script"**ï¼ˆé‡è¦ï¼ï¼‰
   - **description**: ç®€çŸ­æè¿°ï¼ˆå¦‚ "Personal AI trend monitoring"ï¼‰
   - **redirect uri**: å¡«å†™ `http://localhost:8080`ï¼ˆscriptç±»å‹å¿…é¡»å¡«å†™ä½†ä¸ä¼šä½¿ç”¨ï¼‰
4. è®°å½•:
   - **Client ID**: appåç§°ä¸‹æ–¹çš„å­—ç¬¦ä¸²ï¼ˆå¦‚ `abcd1234efgh`ï¼‰
   - **Client Secret**: æ ‡æ³¨ä¸º "secret" çš„é‚£è¡Œ

### é…ç½®ç¯å¢ƒå˜é‡

```bash
# 1. å¤åˆ¶æ¨¡æ¿
cp config/env.example config/.env

# 2. ç¼–è¾‘config/.envï¼Œå¡«å…¥å¯†é’¥
nano config/.env  # æˆ–ä½¿ç”¨ä»»ä½•ç¼–è¾‘å™¨
```

å¿…å¡«å†…å®¹ï¼š
```bash
TWITTER_BEARER_TOKEN=ä½ çš„Twitter_Bearer_Token
REDDIT_CLIENT_ID=ä½ çš„Reddit_Client_ID
REDDIT_CLIENT_SECRET=ä½ çš„Reddit_Client_Secret
REDDIT_USER_AGENT=AI_Trend_Monitor/1.0  # è‡ªå®šä¹‰ï¼Œæ ¼å¼: AppName/Version
```

---

## ç³»ç»Ÿæ¶æ„

### æ•°æ®æµ

```
Twitter/Reddit API
       â†“
Pythoné‡‡é›†å™¨ (æ¯5åˆ†é’Ÿ)
       â†“
Apache Kafka (ai-social-raw topic)
       â†“
Spark Streaming (å®æ—¶å¤„ç†)
       â†“
MinIO + Delta Lake (Bronze/Silver/Gold)
       â†“
Streamlit Dashboard (å®æ—¶å¯è§†åŒ–)
```

### æŠ€æœ¯æ ˆ

| å±‚çº§ | æŠ€æœ¯ | ç”¨é€” |
|------|------|------|
| é‡‡é›† | Tweepy + PRAW | APIæ•°æ®é‡‡é›† |
| é˜Ÿåˆ— | Apache Kafka | æ¶ˆæ¯ç¼“å†² |
| å¤„ç† | Spark Streaming | å®æ—¶ETL |
| å­˜å‚¨ | MinIO + Delta Lake | Lakehouse |
| å¯è§†åŒ– | Streamlit | å®æ—¶Dashboard |
| å®¹å™¨åŒ– | Docker Compose | æœ¬åœ°ç¯å¢ƒ |

### ç›®å½•ç»“æ„

```
lakehouse_ai_pipeline/
â”œâ”€â”€ config/                     # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ .env                    # APIå¯†é’¥ï¼ˆéœ€åˆ›å»ºï¼‰
â”‚   â””â”€â”€ env.example             # æ¨¡æ¿
â”‚
â”œâ”€â”€ data_ingestion/              # æ•°æ®é‡‡é›†
â”‚   â”œâ”€â”€ twitter/collector.py    # Twitterçˆ¬è™«
â”‚   â”œâ”€â”€ reddit/collector.py     # Redditçˆ¬è™«
â”‚   â”œâ”€â”€ kafka_producer.py       # Kafkaç”Ÿäº§è€…
â”‚   â””â”€â”€ config.py               # é…ç½®ç®¡ç†
â”‚
â”œâ”€â”€ streaming/spark/             # Sparkä½œä¸š
â”‚   â”œâ”€â”€ processor_with_minio.py # MinIOå†™å…¥ç‰ˆæœ¬ï¼ˆæ¨èï¼‰
â”‚   â”œâ”€â”€ simple_processor.py     # æ§åˆ¶å°è¾“å‡ºç‰ˆæœ¬
â”‚   â””â”€â”€ jars/                   # Kafka+S3Aè¿æ¥å™¨
â”‚
â”œâ”€â”€ dashboard/                   # å¯è§†åŒ–
â”‚   â”œâ”€â”€ app_realtime.py         # å®æ—¶Dashboardï¼ˆæ¨èï¼‰
â”‚   â””â”€â”€ kafka_reader.py         # Kafkaæ•°æ®è¯»å–
â”‚
â”œâ”€â”€ scripts/                     # å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ 01-full_restart.sh         # å®Œæ•´é‡å¯ + éªŒè¯
â”‚   â”œâ”€â”€ 02-start_spark_minio.sh  # å¯åŠ¨Sparkå†™MinIO
â”‚   â”œâ”€â”€ 03-start_dashboard.sh  # å¯åŠ¨Dashboard
â”‚   â”œâ”€â”€ 99-verify_system.sh        # ç³»ç»Ÿå¥åº·æ£€æŸ¥
â”‚   â”œâ”€â”€ start_collectors.sh     # å¯åŠ¨é‡‡é›†å™¨
â”‚   â”œâ”€â”€ stop_collectors.sh      # åœæ­¢é‡‡é›†å™¨
â”‚   â””â”€â”€ 00-prepare_jars.sh   # ä¸‹è½½Sparkä¾èµ–
â”‚
â”œâ”€â”€ docker-compose-full.yml      # å®Œæ•´åŸºç¡€è®¾æ–½ï¼ˆä½¿ç”¨ä¸­ï¼‰
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–
â””â”€â”€ docs/                        # æ–‡æ¡£
```

### æ•°æ®Schemaè®¾è®¡

#### Bronze Layer (åŸå§‹æ•°æ®)
```python
{
    "source": "twitter" | "reddit",
    "event_timestamp": "ISO8601",
    "raw_data": {...},          # åŸå§‹JSON
    "processed_at": "timestamp",
    "partition_date": "YYYY-MM-DD"
}
```

#### Silver Layer (æ ‡å‡†åŒ–æ•°æ® - è®¡åˆ’ä¸­)
```python
{
    "post_id": "string",
    "source": "string",
    "text": "string",
    "author": "string",
    "created_at": "timestamp",
    "engagement_score": "int",
    "keywords": ["string"],
    "hashtags": ["string"]
}
```

#### Gold Layer (è¶‹åŠ¿èšåˆ - è®¡åˆ’ä¸­)
```python
{
    "topic": "string",
    "hour": "timestamp",
    "mention_count": "int",
    "total_engagement": "int",
    "trend_score": "float"
}
```

---

## å®Œæ•´ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šé¦–æ¬¡å¯åŠ¨ç³»ç»Ÿ

```bash
# 1. é…ç½®APIå¯†é’¥
cp config/env.example config/.env
nano config/.env  # å¡«å…¥Twitterå’ŒReddit APIå¯†é’¥

# 2. ä¸€é”®å®Œæ•´é‡å¯ï¼ˆåŒ…å«æ‰€æœ‰éªŒè¯ï¼‰
./scripts/01-full_restart.sh
# è¿™ä¸ªè„šæœ¬ä¼šï¼š
# - æ£€æŸ¥Dockerã€.envã€venvã€jarä¾èµ–
# - åœæ­¢æ‰€æœ‰ç°æœ‰æœåŠ¡
# - å¯åŠ¨Kafkaã€MinIOã€Sparkã€é‡‡é›†å™¨
# - éªŒè¯æ¯ä¸ªæœåŠ¡å¥åº·çŠ¶æ€
# - ç­‰å¾…æ•°æ®é‡‡é›†å¼€å§‹

# 3. å¯åŠ¨Sparkå†™å…¥MinIOï¼ˆæ–°å»ºç»ˆç«¯ï¼‰
./scripts/02-start_spark_minio.sh
# è¿™ä¼šæ¯30ç§’æ‰¹é‡å†™å…¥æ•°æ®åˆ°MinIO

# 4. å¯åŠ¨Dashboardï¼ˆæ–°å»ºç»ˆç«¯ï¼‰
./scripts/03-start_dashboard.sh
# è®¿é—® http://localhost:8501
```

**é¢„æœŸè¾“å‡º**:
- Kafkaæœ‰500+æ¶ˆæ¯
- MinIOçš„ `lakehouse/bronze/social_media/` æœ‰æ•°æ®
- Spark UIæ˜¾ç¤ºæ´»è·ƒåº”ç”¨
- Dashboardæ˜¾ç¤ºå®æ—¶æ•°æ®

---

### åœºæ™¯2ï¼šæ—¥å¸¸å¯åŠ¨ï¼ˆå·²é…ç½®è¿‡ï¼‰

```bash
# æ–¹å¼1: ä½¿ç”¨ä¸€é”®è„šæœ¬
./scripts/01-full_restart.sh

# æ–¹å¼2: æ‰‹åŠ¨å¯åŠ¨ï¼ˆæ›´çµæ´»ï¼‰
docker-compose -f docker-compose-full.yml up -d
source venv/bin/activate
./scripts/start_collectors.sh
./scripts/02-start_spark_minio.sh  # æ–°å»ºç»ˆç«¯
./scripts/03-start_dashboard.sh  # æ–°å»ºç»ˆç«¯
```

---

### åœºæ™¯3ï¼šéªŒè¯ç³»ç»ŸçŠ¶æ€

```bash
# è¿è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥
./scripts/99-verify_system.sh
```

**æ£€æŸ¥é¡¹**:
- âœ… DockeræœåŠ¡ï¼ˆ5ä¸ªå®¹å™¨ï¼‰
- âœ… ç«¯å£å¯è®¿é—®æ€§ï¼ˆ8080, 9001, 9092ï¼‰
- âœ… æ•°æ®é‡‡é›†å™¨è¿è¡ŒçŠ¶æ€
- âœ… Kafkaæ¶ˆæ¯æ•°é‡
- âœ… MinIOæ•°æ®ï¼ˆé‡ç‚¹ï¼ï¼‰
- âœ… Sparkä½œä¸šçŠ¶æ€

---

### åœºæ™¯4ï¼šæŸ¥çœ‹æ•°æ®å’Œæ—¥å¿—

**æŸ¥çœ‹Kafkaæ¶ˆæ¯**:
```bash
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic ai-social-raw \
  --from-beginning \
  --max-messages 10
```

**æŸ¥çœ‹é‡‡é›†å™¨æ—¥å¿—**:
```bash
# å®æ—¶æŸ¥çœ‹
tail -f logs/twitter_collector.log
tail -f logs/reddit_collector.log

# æŸ¥çœ‹æœ€è¿‘100è¡Œ
tail -100 logs/twitter_collector.log
```

**æŸ¥çœ‹MinIOæ•°æ®**:
1. è®¿é—® http://localhost:9001
2. ç™»å½• (minioadmin/minioadmin)
3. è¿›å…¥ `lakehouse` bucket
4. æŸ¥çœ‹ `bronze/social_media/partition_date=YYYY-MM-DD/` ç›®å½•
5. åº”è¯¥çœ‹åˆ°Parquetæ–‡ä»¶

**å‘½ä»¤è¡ŒæŸ¥çœ‹MinIO**:
```bash
docker exec minio mc ls --recursive myminio/lakehouse/bronze/social_media/
```

**æŸ¥çœ‹Sparkä½œä¸šè¯¦æƒ…**:
- Master UI: http://localhost:8080
- Application UI: http://localhost:4040 (ä½œä¸šè¿è¡Œæ—¶)
- Worker UI: http://localhost:8081

---

### åœºæ™¯5ï¼šåœæ­¢æ‰€æœ‰æœåŠ¡

```bash
# 1. åœæ­¢Spark Streamingï¼ˆæŒ‰ Ctrl+Cï¼‰
# 2. åœæ­¢Dashboardï¼ˆæŒ‰ Ctrl+Cï¼‰
# 3. åœæ­¢é‡‡é›†å™¨
./scripts/stop_collectors.sh

# 4. åœæ­¢åŸºç¡€è®¾æ–½
docker-compose -f docker-compose-full.yml down

# 5. ï¼ˆå¯é€‰ï¼‰åˆ é™¤æ‰€æœ‰æ•°æ®å·
docker-compose -f docker-compose-full.yml down -v
```

---

## æ•…éšœæ’æŸ¥å¤§å…¨

### é—®é¢˜1: Dockeræ— æ³•å¯åŠ¨

**ç—‡çŠ¶**:
```
ERROR: Cannot connect to the Docker daemon
```

**è§£å†³**:
1. æ‰“å¼€Docker Desktop
2. ç­‰å¾…Dockerå®Œå…¨å¯åŠ¨
3. éªŒè¯: `docker ps`

---

### é—®é¢˜2: Spark Workerå¯åŠ¨å¤±è´¥

**ç—‡çŠ¶**:
```
java.io.IOException: Failed to create directory /opt/spark/work/...
Executor 0-9 all failed
```

**åŸå› **: å®¹å™¨ç”¨æˆ·æ²¡æœ‰å†™æƒé™

**è§£å†³**: å·²åœ¨ `docker-compose-full.yml` ä¸­ä¿®å¤
- Workerä»¥rootç”¨æˆ·è¿è¡Œ
- ä½¿ç”¨ `/tmp/spark-work` ä½œä¸ºå·¥ä½œç›®å½•

å¦‚ä»æœ‰é—®é¢˜:
```bash
docker-compose -f docker-compose-full.yml restart spark-worker
docker-compose -f docker-compose-full.yml logs spark-worker
```

---

### é—®é¢˜3: Sparkæ— æ³•ä¸‹è½½Kafkaè¿æ¥å™¨

**ç—‡çŠ¶**:
```
FileNotFoundException: /home/spark/.ivy2/cache/resolved-...
Failed to download org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0
```

**åŸå› **: Mavenä¾èµ–ä¸‹è½½å¤±è´¥ï¼ˆç½‘ç»œæˆ–æƒé™é—®é¢˜ï¼‰

**è§£å†³**: ä½¿ç”¨é¢„ä¸‹è½½jarçš„è„šæœ¬
```bash
# 1. é¢„ä¸‹è½½jaræ–‡ä»¶
./scripts/00-prepare_jars.sh

# 2. ä½¿ç”¨ä¿®å¤åçš„è„šæœ¬å¯åŠ¨Spark
./scripts/02-start_spark_minio.sh
```

ä¸è¦ä½¿ç”¨æ—§çš„ `start_spark_streaming.sh`ï¼ˆå·²å¼ƒç”¨ï¼‰

---

### é—®é¢˜4: Twitter API 401é”™è¯¯

**ç—‡çŠ¶**:
```
tweepy.errors.Unauthorized: 401 Unauthorized
```

**å¯èƒ½åŸå› **:
- Bearer Tokené”™è¯¯æˆ–è¿‡æœŸ
- ä½¿ç”¨äº†é”™è¯¯çš„Tokenç±»å‹ï¼ˆåº”è¯¥ç”¨Bearer Tokenï¼Œä¸æ˜¯API Keyï¼‰

**è§£å†³**:
1. æ£€æŸ¥ `config/.env` ä¸­çš„ `TWITTER_BEARER_TOKEN`
2. ç¡®è®¤Twitter Developerè´¦å·çŠ¶æ€
3. æµ‹è¯•è¿æ¥:

```bash
source venv/bin/activate
python -c "
import os
from dotenv import load_dotenv
load_dotenv('config/.env')
token = os.getenv('TWITTER_BEARER_TOKEN')
print(f'Tokenå­˜åœ¨: {bool(token)}')
print(f'Tokené•¿åº¦: {len(token) if token else 0}')
print(f'Tokenå‰ç¼€: {token[:20] if token else \"æ— \"}...')
"
```

---

### é—®é¢˜5: Redditè¿æ¥å¤±è´¥

**ç—‡çŠ¶**:
```
prawcore.exceptions.NotFound: received 404 HTTP response
prawcore.exceptions.TooManyRequests: received 429 HTTP response
```

**å¯èƒ½åŸå› **:
- Subredditåç§°é”™è¯¯æˆ–ä¸å­˜åœ¨
- APIé™æµï¼ˆè¯·æ±‚è¿‡äºé¢‘ç¹ï¼‰
- redirect_uriæœªæ­£ç¡®é…ç½®

**è§£å†³**:

**5.1 æ£€æŸ¥Subredditåç§°**:
ç¼–è¾‘ `data_ingestion/reddit/collector.py`ï¼Œæ³¨é‡Šæ‰é—®é¢˜subreddit:
```python
TARGET_SUBREDDITS = [
    'MachineLearning',
    'LocalLLaMA',
    # 'ArtificialIntelligence',  # æš‚æ—¶ç¦ç”¨
]
```

**5.2 å¢åŠ é‡‡é›†é—´éš”**:
ç¼–è¾‘ `config/.env`:
```bash
REDDIT_COLLECTION_INTERVAL=600  # æ”¹ä¸º10åˆ†é’Ÿ
```

**5.3 éªŒè¯APIé…ç½®**:
```bash
python -c "
import praw
from dotenv import load_dotenv
import os
load_dotenv('config/.env')

reddit = praw.Reddit(
    client_id=os.getenv('REDDIT_CLIENT_ID'),
    client_secret=os.getenv('REDDIT_CLIENT_SECRET'),
    user_agent=os.getenv('REDDIT_USER_AGENT')
)
print('åªè¯»æ¨¡å¼:', reddit.read_only)
print('å¯ä»¥è®¿é—®:', reddit.user.me() is None)
"
```

---

### é—®é¢˜6: Dashboardæ— æ•°æ®

**ç—‡çŠ¶**: Dashboardæ˜¾ç¤º "No data available"

**æ£€æŸ¥æ¸…å•**:

```bash
# 1. Kafkaæ˜¯å¦æœ‰æ•°æ®ï¼Ÿ
docker exec kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic ai-social-raw

# 2. é‡‡é›†å™¨æ˜¯å¦è¿è¡Œï¼Ÿ
ps aux | grep collector

# 3. æŸ¥çœ‹é‡‡é›†å™¨æ—¥å¿—
tail -20 logs/twitter_collector.log
tail -20 logs/reddit_collector.log

# 4. æ‰‹åŠ¨æ¶ˆè´¹Kafkaæµ‹è¯•
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic ai-social-raw \
  --from-beginning \
  --max-messages 5
```

**å¸¸è§è§£å†³æ–¹æ¡ˆ**:
- é‡‡é›†å™¨æœªè¿è¡Œ â†’ `./scripts/start_collectors.sh`
- APIå¯†é’¥é”™è¯¯ â†’ æ£€æŸ¥ `config/.env`
- Kafkaæœªå¯åŠ¨ â†’ `docker-compose -f docker-compose-full.yml up -d`

---

### é—®é¢˜7: ç«¯å£å ç”¨

**ç—‡çŠ¶**:
```
Port 8080 is already in use
Error starting userland proxy: listen tcp4 0.0.0.0:9092: bind: address already in use
```

**è§£å†³**:

```bash
# æŸ¥æ‰¾å ç”¨è¿›ç¨‹
lsof -i :8080
lsof -i :9092

# åœæ­¢å†²çªæœåŠ¡
docker-compose -f docker-compose-full.yml down

# æˆ–æ€æ‰è¿›ç¨‹ï¼ˆè°¨æ…ï¼ï¼‰
kill -9 <PID>
```

---

### é—®é¢˜8: MinIOæ²¡æœ‰æ•°æ®

**ç—‡çŠ¶**: è®¿é—®MinIO Consoleçœ‹ä¸åˆ° `bronze/social_media/` æ•°æ®

**åŸå› **: å¯èƒ½è¿˜åœ¨ç”¨æ—§çš„æ§åˆ¶å°è¾“å‡ºç‰ˆSparkå¤„ç†å™¨

**è§£å†³**:

```bash
# 1. åœæ­¢æ—§çš„Sparkä½œä¸šï¼ˆå¦‚æœæœ‰ï¼‰
# åœ¨è¿è¡ŒSparkçš„ç»ˆç«¯æŒ‰ Ctrl+C

# 2. ä½¿ç”¨MinIOå†™å…¥ç‰ˆæœ¬
./scripts/02-start_spark_minio.sh

# 3. ç­‰å¾…30ç§’ï¼ˆç¬¬ä¸€ä¸ªæ‰¹æ¬¡ï¼‰

# 4. éªŒè¯MinIOæ•°æ®
docker exec minio mc ls --recursive myminio/lakehouse/bronze/social_media/

# 5. æˆ–è®¿é—® http://localhost:9001 æŸ¥çœ‹
```

---

### é—®é¢˜9: Sparkä½œä¸šå†…å­˜ä¸è¶³

**ç—‡çŠ¶**:
```
Container killed by YARN for exceeding memory limits
java.lang.OutOfMemoryError: Java heap space
```

**è§£å†³**:

ç¼–è¾‘ `scripts/02-start_spark_minio.sh`ï¼Œå¢åŠ å†…å­˜é…ç½®:
```bash
--conf spark.executor.memory=2g \
--conf spark.driver.memory=2g \
```

ç¡®ä¿Docker Desktopåˆ†é…è¶³å¤Ÿå†…å­˜ï¼ˆè®¾ç½® â†’ Resources â†’ Memory â†’ è‡³å°‘4GBï¼‰

---

### é—®é¢˜10: Docker Composeè­¦å‘Š

**ç—‡çŠ¶**:
```
WARN[0000] /path/to/docker-compose.yml: `version` is obsolete
```

**è§£å†³**: è¿™åªæ˜¯è­¦å‘Šï¼Œä¸å½±å“è¿è¡Œ

å¦‚æƒ³æ¶ˆé™¤:
```bash
# ç¼–è¾‘docker-compose-full.ymlï¼Œåˆ é™¤ç¬¬ä¸€è¡Œçš„versionå­—æ®µ
sed -i.bak '1d' docker-compose-full.yml
```

---

## å‘½ä»¤é€ŸæŸ¥è¡¨

### å¯åŠ¨ç›¸å…³
```bash
./scripts/01-full_restart.sh                 # å®Œæ•´é‡å¯ + éªŒè¯æ‰€æœ‰ç»„ä»¶
./scripts/02-start_spark_minio.sh       # å¯åŠ¨Sparkå†™MinIO
./scripts/03-start_dashboard.sh     # å¯åŠ¨Dashboard
./scripts/start_collectors.sh             # å¯åŠ¨é‡‡é›†å™¨
```

### åœæ­¢ç›¸å…³
```bash
./scripts/stop_collectors.sh              # åœæ­¢é‡‡é›†å™¨
docker-compose -f docker-compose-full.yml down  # åœæ­¢åŸºç¡€è®¾æ–½
docker-compose -f docker-compose-full.yml down -v  # åœæ­¢å¹¶åˆ é™¤æ•°æ®
```

### æŸ¥çœ‹ç›¸å…³
```bash
# ç³»ç»ŸçŠ¶æ€
./scripts/99-verify_system.sh                # å®Œæ•´å¥åº·æ£€æŸ¥
docker ps                                 # æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker-compose -f docker-compose-full.yml logs -f  # æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—

# é‡‡é›†å™¨æ—¥å¿—
tail -f logs/twitter_collector.log        # Twitterå®æ—¶æ—¥å¿—
tail -f logs/reddit_collector.log         # Redditå®æ—¶æ—¥å¿—

# Kafka
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic ai-social-raw \
  --from-beginning \
  --max-messages 10                       # æŸ¥çœ‹æ¶ˆæ¯

# MinIO
docker exec minio mc ls --recursive myminio/lakehouse/bronze/social_media/
```

### æµ‹è¯•ç›¸å…³
```bash
curl http://localhost:8080                # æµ‹è¯•Spark Master
curl http://localhost:9000/minio/health/live  # æµ‹è¯•MinIO
curl http://localhost:9001                # æµ‹è¯•MinIO Console
```

### é‡ç½®ç³»ç»Ÿ
```bash
# å®Œå…¨é‡ç½®ï¼ˆåˆ é™¤æ‰€æœ‰æ•°æ®ï¼‰
./scripts/stop_collectors.sh
docker-compose -f docker-compose-full.yml down -v
rm -rf logs/*.log
# ç„¶åé‡æ–°å¯åŠ¨
./scripts/01-full_restart.sh
```

---

## æ‰©å±•è·¯çº¿å›¾

### âœ… å·²å®Œæˆ

- [x] Phase 1: MVPæ¶æ„æ­å»º
- [x] Phase 2A: Dashboardå®æ—¶å±•ç¤º
- [x] Phase 2B: Spark Streamingé›†æˆ
- [x] Phase 2C: MinIOæŒä¹…åŒ–ï¼ˆBronzeå±‚ï¼‰

### ğŸ”„ Phase 3: Delta Lakeå®Œæ•´å®ç°ï¼ˆä¸‹ä¸€æ­¥ï¼‰

**ç›®æ ‡**: å®ç°å®Œæ•´çš„Bronze/Silver/Goldä¸‰å±‚æ¶æ„

**ä»»åŠ¡**:
1. ä¿®æ”¹ `streaming/spark/processor_with_minio.py`
2. æ·»åŠ Delta Lakeæ ¼å¼å†™å…¥ï¼ˆæ›¿ä»£Parquetï¼‰
3. å®ç°Silverå±‚æ•°æ®æ¸…æ´—:
   - å»é‡ï¼ˆåŸºäºpost_idï¼‰
   - æ–‡æœ¬æ ‡å‡†åŒ–
   - å…³é”®è¯æå–
4. å®ç°Goldå±‚èšåˆ:
   - æŒ‰å°æ—¶èšåˆè¶‹åŠ¿
   - çƒ­ç‚¹è¯é¢˜æ’å
   - ç”¨æˆ·æ´»è·ƒåº¦ç»Ÿè®¡
5. Dashboardè¿æ¥Delta Lakeè¯»å–

**é¢„è®¡æ—¶é—´**: 1-2å‘¨

---

### ğŸ“… Phase 4: å‘é‡æœç´¢å’ŒRAGï¼ˆ2-3å‘¨åï¼‰

**ç›®æ ‡**: è¯­ä¹‰æœç´¢å’Œæ™ºèƒ½é—®ç­”

**æŠ€æœ¯æ ˆ**:
- Milvusï¼ˆå‘é‡æ•°æ®åº“ï¼‰
- Sentence Transformersï¼ˆæ–‡æœ¬embeddingï¼‰
- LangChain + OpenAI/Claude API

**åŠŸèƒ½**:
- è¯­ä¹‰ç›¸ä¼¼æœç´¢ï¼š"æ‰¾å‡ºæ‰€æœ‰å…³äºGPT-5çš„è®¨è®º"
- è‡ªç„¶è¯­è¨€é—®ç­”ï¼š"æœ€è¿‘å¤§å®¶å¯¹Claudeçš„è¯„ä»·å¦‚ä½•ï¼Ÿ"
- è¶‹åŠ¿é¢„æµ‹ï¼š"å“ªä¸ªAIè¯é¢˜æœ€è¿‘çƒ­åº¦ä¸Šå‡æœ€å¿«ï¼Ÿ"

**å®æ–½æ­¥éª¤**:
1. æ·»åŠ Milvusåˆ° `docker-compose-full.yml`
2. å®ç°æ–‡æœ¬å‘é‡åŒ– Pipeline
3. æ„å»ºRAGé—®ç­”æ¥å£
4. Dashboardæ·»åŠ æœç´¢åŠŸèƒ½

---

### ğŸš€ Phase 5: ç”Ÿäº§åŒ–éƒ¨ç½²ï¼ˆ1ä¸ªæœˆåï¼‰

**ç›®æ ‡**: éƒ¨ç½²åˆ°äº‘ç«¯ï¼Œå®ç°é«˜å¯ç”¨

**æ”¹è¿›ç‚¹**:
- **äº‘ç«¯è¿ç§»**: AWS S3 + EMR æˆ– Azure HDInsight
- **Kafkaé›†ç¾¤**: 3èŠ‚ç‚¹é«˜å¯ç”¨é…ç½®
- **Spark HA**: å¤šMaster + Zookeeperåè°ƒ
- **ç›‘æ§å‘Šè­¦**: Prometheus + Grafana + AlertManager
- **CI/CD**: GitHub Actionsè‡ªåŠ¨éƒ¨ç½²
- **æˆæœ¬ä¼˜åŒ–**: S3ç”Ÿå‘½å‘¨æœŸç­–ç•¥ï¼ŒSpotå®ä¾‹

---

## æ€§èƒ½æŒ‡æ ‡

### å½“å‰ç³»ç»Ÿå®¹é‡

| æŒ‡æ ‡ | å½“å‰å€¼ | ç†è®ºä¸Šé™ |
|------|--------|----------|
| é‡‡é›†é¢‘ç‡ | 5åˆ†é’Ÿ/æ¬¡ | APIé™åˆ¶ |
| Kafkaåå | ~100msg/s | 10K msg/s |
| Sparkå¤„ç†å»¶è¿Ÿ | <30ç§’ | <1ç§’ |
| å­˜å‚¨ | MinIOæ— é™ | ç£ç›˜ç©ºé—´ |
| æ•°æ®ä¿ç•™ | Kafka 7å¤© | å¯é…ç½® |

### èµ„æºä½¿ç”¨

- **Dockerå†…å­˜**: å»ºè®®4GB+ï¼ˆå½“å‰é…ç½®ï¼‰
- **ç£ç›˜ç©ºé—´**: 10GB+ï¼ˆæ•°æ®å¢é•¿ï¼‰
- **CPU**: 2æ ¸å¿ƒ+
- **ç½‘ç»œ**: éœ€ç¨³å®šè¿æ¥ï¼ˆAPIè°ƒç”¨ï¼‰

---

## è·å–å¸®åŠ©

### æ—¥å¿—ä½ç½®

- é‡‡é›†å™¨æ—¥å¿—: `logs/*.log`
- Sparkæ—¥å¿—: `docker-compose -f docker-compose-full.yml logs spark-master`
- Kafkaæ—¥å¿—: `docker-compose -f docker-compose-full.yml logs kafka`
- MinIOæ—¥å¿—: `docker-compose -f docker-compose-full.yml logs minio`

### è°ƒè¯•æŠ€å·§

1. **ä»ä¸Šæ¸¸åˆ°ä¸‹æ¸¸æ’æŸ¥**:
   ```
   API â†’ é‡‡é›†å™¨ â†’ Kafka â†’ Spark â†’ MinIO â†’ Dashboard
   ```

2. **ä½¿ç”¨99-verify_system.sh**:
   ```bash
   ./scripts/99-verify_system.sh
   ```

3. **æŸ¥çœ‹Dockeræ—¥å¿—**:
   ```bash
   docker-compose -f docker-compose-full.yml logs -f --tail=100
   ```

4. **è¿›å…¥å®¹å™¨è°ƒè¯•**:
   ```bash
   docker exec -it spark-master bash
   docker exec -it kafka bash
   docker exec -it minio bash
   ```

---

## å­¦ä¹ èµ„æº

### å¿…è¯»æ–‡æ¡£

- [Delta Lakeå®˜æ–¹æ–‡æ¡£](https://docs.delta.io/)
- [Spark Structured Streamingç¼–ç¨‹æŒ‡å—](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Kafkaæ–‡æ¡£](https://kafka.apache.org/documentation/)
- [MinIOæ–‡æ¡£](https://min.io/docs/)

### æ¨èè¯¾ç¨‹

- DataTalksClub - Data Engineering Zoomcamp
- Databricks Academy - Lakehouse Fundamentals
- Apache Sparkå®˜æ–¹æ•™ç¨‹

### ç›¸å…³é¡¹ç›®å‚è€ƒ

- [Awesome Data Engineering](https://github.com/igorbarinov/awesome-data-engineering)
- [Real-time Stream Processing Examples](https://github.com/topics/stream-processing)

---

## é¡¹ç›®æˆæœ

é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œä½ å·²ç»æŒæ¡:

âœ… **æ•°æ®å·¥ç¨‹æŠ€èƒ½**
- å®Œæ•´çš„ETL pipelineæ­å»º
- å®æ—¶æ•°æ®å¤„ç†ï¼ˆStreamingï¼‰
- Lakehouseæ¶æ„å®è·µ

âœ… **æŠ€æœ¯æ ˆå®è·µ**
- Dockerå®¹å™¨åŒ–éƒ¨ç½²
- Apache Kafkaæ¶ˆæ¯é˜Ÿåˆ—
- Sparkåˆ†å¸ƒå¼è®¡ç®—
- Pythonæ•°æ®é‡‡é›†å’Œå¤„ç†
- MinIOå¯¹è±¡å­˜å‚¨

âœ… **é¡¹ç›®ç®¡ç†èƒ½åŠ›**
- åˆ†é˜¶æ®µå®æ–½ï¼ˆMVP â†’ Phase 2 â†’ Phase 3ï¼‰
- é—®é¢˜æ’æŸ¥å’Œè§£å†³
- æ–‡æ¡£ç¼–å†™å’Œç»´æŠ¤

---

**æ­å–œä½ å®Œæˆäº†Phase 2Bï¼** ğŸ‰

ç³»ç»Ÿç°åœ¨å¯ä»¥:
- âœ… å®æ—¶é‡‡é›†Twitterå’ŒRedditæ•°æ®
- âœ… é€šè¿‡Kafkaä¼ è¾“
- âœ… Sparkå®æ—¶å¤„ç†
- âœ… å†™å…¥MinIOæŒä¹…åŒ–å­˜å‚¨
- âœ… Dashboardå¯è§†åŒ–å±•ç¤º

**ä¸‹ä¸€ä¸ªé‡Œç¨‹ç¢‘**: å®ç°Delta Lakeå®Œæ•´ä¸‰å±‚æ¶æ„ ğŸš€

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0
**æœ€åæ›´æ–°**: 2025-11-11
**ç»´æŠ¤è€…**: Guangyao Li
**é¡¹ç›®å¼€å§‹**: 2025-11-11
