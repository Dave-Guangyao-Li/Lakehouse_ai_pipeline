# æ•…éšœæ’æŸ¥æ‰‹å†Œ

è®°å½•æ‰€æœ‰è¸©è¿‡çš„å‘å’Œè§£å†³æ–¹æ¡ˆã€‚

---

## ğŸ› å·²è§£å†³çš„é—®é¢˜

### 1. Sparké•œåƒç‰ˆæœ¬é—®é¢˜

**é—®é¢˜ï¼š** `bitnami/spark:3.4.1` é•œåƒæ‰¾ä¸åˆ°

**é”™è¯¯ä¿¡æ¯ï¼š**
```
Error: failed to resolve reference "docker.io/bitnami/spark:3.4.1": not found
```

**å°è¯•çš„è§£å†³æ–¹æ¡ˆï¼š**
- âŒ å‡çº§åˆ° 3.5.0 â†’ ä»ç„¶å¤±è´¥
- âŒ ä½¿ç”¨Dockeré•œåƒåŠ é€Ÿ â†’ æœªè§£å†³æ ¹æœ¬é—®é¢˜

**æœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼š**
âœ… åˆ‡æ¢åˆ°Apacheå®˜æ–¹é•œåƒ `apache/spark:3.5.0-python3`

**ä¿®æ”¹ä½ç½®ï¼š** `docker-compose-full.yml`

---

### 2. Spark Workeræƒé™é”™è¯¯

**é—®é¢˜ï¼š** Workeræ— æ³•åˆ›å»ºå·¥ä½œç›®å½•

**é”™è¯¯ä¿¡æ¯ï¼š**
```
java.io.IOException: Failed to create directory /opt/spark/work/app-xxx/0
```

**æ ¹æœ¬åŸå› ï¼š** å®¹å™¨å†…æ™®é€šç”¨æˆ·æ²¡æœ‰ `/opt/spark/work` å†™æƒé™

**è§£å†³æ–¹æ¡ˆï¼š**
1. Workerä»¥rootç”¨æˆ·è¿è¡Œï¼š`user: root`
2. ä½¿ç”¨ `/tmp` ç›®å½•ï¼š`SPARK_WORKER_DIR=/tmp/spark-work`
3. Volumeæ˜ å°„åˆ° `/tmp`

**ä¿®æ”¹ä½ç½®ï¼š** `docker-compose-full.yml` spark-workeré…ç½®

---

### 3. Sparkæ— æ³•ä¸‹è½½Mavenä¾èµ–

**é—®é¢˜ï¼š** Sparkå°è¯•åœ¨çº¿ä¸‹è½½Kafkaè¿æ¥å™¨å¤±è´¥

**é”™è¯¯ä¿¡æ¯ï¼š**
```
FileNotFoundException: /home/spark/.ivy2/cache/resolved-org.apache.spark-...
```

**æ ¹æœ¬åŸå› ï¼š**
- å®¹å™¨å†…Ivyç¼“å­˜ç›®å½•æ— å†™æƒé™
- Mavenä»“åº“è¿æ¥å¤±è´¥/æ…¢

**è§£å†³æ–¹æ¡ˆï¼š**
é¢„å…ˆä¸‹è½½jaræ–‡ä»¶å¹¶é€šè¿‡ `--jars` å‚æ•°æä¾›

**å®æ–½ï¼š**
1. åˆ›å»º `prepare_spark_jars.sh` ä¸‹è½½ä¾èµ–
2. åˆ›å»º `start_spark_streaming_fixed.sh` ä½¿ç”¨æœ¬åœ°jar
3. åºŸå¼ƒåŸ `start_spark_streaming.sh`

---

### 4. Reddit API redirect_urié—®é¢˜

**é—®é¢˜ï¼š** åˆ›å»ºRedditåº”ç”¨æ—¶å¿…é¡»å¡«å†™redirect_uri

**è¯¯åŒºï¼š** "script"ç±»å‹åº”ç”¨ä¸éœ€è¦redirect URI

**å®é™…æƒ…å†µï¼š** Redditè¡¨å•éªŒè¯å¼ºåˆ¶è¦æ±‚å¡«å†™

**è§£å†³æ–¹æ¡ˆï¼š** å¡«å†™ `http://localhost:8080`ï¼ˆä¸ä¼šå®é™…ä½¿ç”¨ï¼‰

**æ–‡æ¡£æ›´æ–°ï¼š** `QUICKSTART.md` æ·»åŠ è¯¦ç»†è¯´æ˜

---

### 5. Docker Compose versionè­¦å‘Š

**é—®é¢˜ï¼š**
```
WARN: the attribute `version` is obsolete
```

**è§£å†³æ–¹æ¡ˆï¼š** åˆ é™¤ `version: '3.8'` è¡Œ

**å½±å“ï¼š** ä¸å½±å“åŠŸèƒ½ï¼Œä½†æ¸…ç†è­¦å‘Š

---

## ğŸ” è°ƒè¯•æŠ€å·§

### æŸ¥çœ‹å®¹å™¨æ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹
docker-compose -f docker-compose-full.yml logs -f <service-name>

# æŸ¥çœ‹æœ€è¿‘100è¡Œ
docker-compose -f docker-compose-full.yml logs --tail=100 <service-name>

# ç¤ºä¾‹
docker-compose -f docker-compose-full.yml logs --tail=50 spark-worker
```

### è¿›å…¥å®¹å™¨è°ƒè¯•

```bash
# è¿›å…¥å®¹å™¨
docker exec -it <container-name> bash

# ç¤ºä¾‹ï¼šæ£€æŸ¥Spark Worker
docker exec -it spark-worker bash
ls -la /tmp/spark-work
ps aux | grep spark
```

### æµ‹è¯•ç½‘ç»œè¿é€šæ€§

```bash
# å®¹å™¨é—´é€šä¿¡
docker exec spark-worker ping spark-master
docker exec spark-master nc -zv kafka 29092

# ä¸»æœºåˆ°å®¹å™¨
curl http://localhost:8080
```

### æ¸…ç†å¹¶é‡å¯

```bash
# å®Œå…¨æ¸…ç†
docker-compose -f docker-compose-full.yml down -v
docker system prune -f

# é‡æ–°å¯åŠ¨
docker-compose -f docker-compose-full.yml up -d
```

---

## âš ï¸ å¸¸è§é™·é˜±

### 1. ä½¿ç”¨é”™è¯¯çš„Kafkaåœ°å€

**é”™è¯¯ï¼š** åœ¨Sparkä¸­ä½¿ç”¨ `localhost:9092`

**æ­£ç¡®ï¼š**
- å®¹å™¨å†…éƒ¨ï¼š`kafka:29092`
- ä¸»æœºè®¿é—®ï¼š`localhost:9092`

### 2. å¿˜è®°æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

**é”™è¯¯ï¼š** ç›´æ¥è¿è¡ŒPythonè„šæœ¬

**æ­£ç¡®ï¼š**
```bash
source venv/bin/activate
```

### 3. APIå¯†é’¥æœªé…ç½®

**æ£€æŸ¥ï¼š**
```bash
cat config/.env | grep TWITTER_BEARER_TOKEN
```

### 4. ç«¯å£å†²çª

**å¸¸è§ç«¯å£ï¼š**
- 8080 (Spark Master)
- 8501 (Streamlit)
- 9092 (Kafka)

**æ£€æŸ¥å ç”¨ï¼š**
```bash
lsof -i :8080
```

---

## ğŸ“ é—®é¢˜æŠ¥å‘Šæ¨¡æ¿

é‡åˆ°æ–°é—®é¢˜æ—¶ï¼Œè®°å½•ä»¥ä¸‹ä¿¡æ¯ï¼š

```
### é—®é¢˜æè¿°


### å¤ç°æ­¥éª¤
1.
2.
3.

### é”™è¯¯ä¿¡æ¯
```
ç²˜è´´é”™è¯¯æ—¥å¿—
```

### ç¯å¢ƒä¿¡æ¯
- OS:
- Dockerç‰ˆæœ¬:
- Pythonç‰ˆæœ¬:

### å°è¯•çš„è§£å†³æ–¹æ¡ˆ
1.
2.

### æœ€ç»ˆè§£å†³æ–¹æ¡ˆ


### ç›¸å…³æ–‡ä»¶
-
```

---

**æ›´æ–°æ—¥å¿—**

- 2025-11-11: åˆå§‹ç‰ˆæœ¬ï¼Œè®°å½•Phase 2Bé—®é¢˜
