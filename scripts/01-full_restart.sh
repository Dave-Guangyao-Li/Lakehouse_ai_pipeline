#!/bin/bash
# å®Œæ•´é‡å¯è„šæœ¬ - ä»å¤´åˆ°å°¾éªŒè¯æ¯ä¸€æ­¥

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ğŸ”„ AIè¶‹åŠ¿ç›‘æ§ç³»ç»Ÿ - å®Œæ•´é‡å¯"
echo "================================"
echo ""

# é¢œè‰²å®šä¹‰
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Step 0: æ£€æŸ¥å‰ç½®æ¡ä»¶
echo "ğŸ“‹ Step 0: æ£€æŸ¥å‰ç½®æ¡ä»¶"
echo "--------------------------------"

if ! docker info > /dev/null 2>&1; then
    echo -e "${RED}âŒ Dockeræœªè¿è¡Œï¼è¯·å…ˆå¯åŠ¨Docker Desktop${NC}"
    exit 1
fi
echo -e "${GREEN}âœ… Dockeræ­£åœ¨è¿è¡Œ${NC}"

if [ ! -f "config/.env" ]; then
    echo -e "${RED}âŒ config/.envä¸å­˜åœ¨ï¼${NC}"
    echo "è¯·è¿è¡Œ: cp config/env.example config/.env"
    echo "ç„¶åç¼–è¾‘å¡«å…¥APIå¯†é’¥"
    exit 1
fi
echo -e "${GREEN}âœ… config/.envå­˜åœ¨${NC}"

if [ ! -d "venv" ]; then
    echo -e "${YELLOW}âš ï¸  è™šæ‹Ÿç¯å¢ƒä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸­...${NC}"
    python3 -m venv venv
fi
echo -e "${GREEN}âœ… Pythonè™šæ‹Ÿç¯å¢ƒå°±ç»ª${NC}"

if [ ! -f "streaming/spark/jars/spark-sql-kafka-0-10_2.12-3.5.0.jar" ]; then
    echo -e "${YELLOW}âš ï¸  Spark jarä¸å­˜åœ¨ï¼Œä¸‹è½½ä¸­...${NC}"
    ./scripts/prepare_spark_jars.sh
fi
echo -e "${GREEN}âœ… Sparkä¾èµ–å°±ç»ª${NC}"

echo ""

# Step 1: åœæ­¢æ‰€æœ‰æœåŠ¡
echo "ğŸ›‘ Step 1: åœæ­¢æ‰€æœ‰ç°æœ‰æœåŠ¡"
echo "--------------------------------"
docker-compose -f docker-compose-full.yml down 2>/dev/null || true
./scripts/stop_collectors.sh 2>/dev/null || true
echo -e "${GREEN}âœ… æ‰€æœ‰æœåŠ¡å·²åœæ­¢${NC}"
echo ""

# Step 2: å¯åŠ¨åŸºç¡€è®¾æ–½
echo "ğŸš€ Step 2: å¯åŠ¨åŸºç¡€è®¾æ–½"
echo "--------------------------------"
docker-compose -f docker-compose-full.yml up -d

echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨ï¼ˆ30ç§’ï¼‰..."
sleep 30

# éªŒè¯æ¯ä¸ªæœåŠ¡
echo ""
echo "ğŸ” éªŒè¯æœåŠ¡çŠ¶æ€..."

# æ£€æŸ¥Kafka
if docker exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092 > /dev/null 2>&1; then
    echo -e "${GREEN}âœ… Kafkaå°±ç»ª${NC}"
else
    echo -e "${RED}âŒ Kafkaæœªå°±ç»ª${NC}"
    exit 1
fi

# æ£€æŸ¥MinIO
if curl -f http://localhost:9000/minio/health/live > /dev/null 2>&1; then
    echo -e "${GREEN}âœ… MinIOå°±ç»ª${NC}"
else
    echo -e "${RED}âŒ MinIOæœªå°±ç»ª${NC}"
    exit 1
fi

# æ£€æŸ¥Spark Master
if curl -f http://localhost:8080 > /dev/null 2>&1; then
    echo -e "${GREEN}âœ… Spark Masterå°±ç»ª${NC}"
else
    echo -e "${RED}âŒ Spark Masteræœªå°±ç»ª${NC}"
    exit 1
fi

# æ£€æŸ¥Spark Worker
if curl -f http://localhost:8081 > /dev/null 2>&1; then
    echo -e "${GREEN}âœ… Spark Workerå°±ç»ª${NC}"
else
    echo -e "${RED}âŒ Spark Workeræœªå°±ç»ª${NC}"
    exit 1
fi

echo ""

# Step 3: å¯åŠ¨é‡‡é›†å™¨
echo "ğŸ“¡ Step 3: å¯åŠ¨æ•°æ®é‡‡é›†å™¨"
echo "--------------------------------"
source venv/bin/activate

# å¯åŠ¨é‡‡é›†å™¨
./scripts/start_collectors.sh

echo "â³ ç­‰å¾…é‡‡é›†å™¨æ”¶é›†æ•°æ®ï¼ˆ15ç§’ï¼‰..."
sleep 15

# éªŒè¯é‡‡é›†å™¨
if ps aux | grep -q "[c]ollector.py"; then
    echo -e "${GREEN}âœ… é‡‡é›†å™¨æ­£åœ¨è¿è¡Œ${NC}"

    # æ£€æŸ¥æ—¥å¿—
    if [ -f "logs/twitter_collector.log" ]; then
        TWITTER_LINES=$(tail -20 logs/twitter_collector.log | grep -c "Sent tweet" || echo 0)
        echo -e "${GREEN}   Twitter: ${TWITTER_LINES} æ¡æ¨æ–‡å·²å‘é€${NC}"
    fi

    if [ -f "logs/reddit_collector.log" ]; then
        REDDIT_LINES=$(tail -20 logs/reddit_collector.log | grep -c "Sent Reddit post" || echo 0)
        echo -e "${GREEN}   Reddit: ${REDDIT_LINES} ä¸ªå¸–å­å·²å‘é€${NC}"
    fi
else
    echo -e "${RED}âŒ é‡‡é›†å™¨æœªè¿è¡Œ${NC}"
    exit 1
fi

echo ""

# Step 4: éªŒè¯Kafkaæ•°æ®
echo "ğŸ“Š Step 4: éªŒè¯Kafkaæ•°æ®"
echo "--------------------------------"

# æ£€æŸ¥Kafkaæ¶ˆæ¯æ•°é‡
KAFKA_COUNT=$(docker exec kafka kafka-run-class kafka.tools.GetOffsetShell \
    --broker-list localhost:9092 \
    --topic ai-social-raw 2>/dev/null | awk -F':' '{sum+=$NF} END {print sum}')

if [ "$KAFKA_COUNT" -gt 0 ]; then
    echo -e "${GREEN}âœ… Kafkaæœ‰ ${KAFKA_COUNT} æ¡æ¶ˆæ¯${NC}"
else
    echo -e "${YELLOW}âš ï¸  Kafkaæš‚æ—¶æ²¡æœ‰æ¶ˆæ¯ï¼Œç­‰å¾…é‡‡é›†å™¨...${NC}"
fi

echo ""

# Step 5: æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
echo "ğŸ“ˆ Step 5: ç³»ç»ŸçŠ¶æ€æ€»è§ˆ"
echo "================================"
echo ""
echo "ğŸ¯ è¿è¡Œä¸­çš„æœåŠ¡:"
docker-compose -f docker-compose-full.yml ps
echo ""

echo "ğŸŒ è®¿é—®ç‚¹:"
echo "   - Spark Master UI:  http://localhost:8080"
echo "   - Spark Worker UI:  http://localhost:8081"
echo "   - MinIO Console:    http://localhost:9001"
echo "   - Spark App UI:     http://localhost:4040 (Sparkè¿è¡Œå)"
echo ""

echo "ğŸ“Š æ•°æ®ç»Ÿè®¡:"
echo "   - Kafkaæ¶ˆæ¯æ•°: ${KAFKA_COUNT}"
echo "   - é‡‡é›†å™¨çŠ¶æ€: $(ps aux | grep -c "[c]ollector.py") ä¸ªè¿›ç¨‹è¿è¡Œä¸­"
echo ""

echo "âœ… åŸºç¡€è®¾æ–½å¯åŠ¨å®Œæˆï¼"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ“ ä¸‹ä¸€æ­¥æ“ä½œ:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "1ï¸âƒ£  å¯åŠ¨Spark Streaming (å†™å…¥MinIO):"
echo "   ./scripts/start_spark_with_minio.sh"
echo ""
echo "2ï¸âƒ£  æŸ¥çœ‹å®æ—¶å¤„ç†æ—¥å¿—:"
echo "   tail -f logs/twitter_collector.log"
echo ""
echo "3ï¸âƒ£  å¯åŠ¨Dashboard:"
echo "   ./scripts/start_dashboard_realtime.sh"
echo ""
echo "4ï¸âƒ£  éªŒè¯MinIOæ•°æ®:"
echo "   è®¿é—® http://localhost:9001"
echo "   æŸ¥çœ‹ 'lakehouse' bucket"
echo ""
echo "ğŸ›‘ åœæ­¢æ‰€æœ‰æœåŠ¡:"
echo "   ./scripts/stop_collectors.sh"
echo "   docker-compose -f docker-compose-full.yml down"
echo ""
